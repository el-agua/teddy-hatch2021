# -*- coding: utf-8 -*-
"""Copy of Copy of Working label model NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fi5oxvaldla8cuy1WeIZEHYm_2CirTPA
"""

from google.colab import drive
drive.mount('/content/drive')

datadir = '/content/drive/My Drive/domodata.csv'

import numpy as np
import pandas
import seaborn as sns
import matplotlib.pyplot as plt

import tensorflow as tf
import tensorflow_hub as hub


from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit, train_test_split
from imblearn.over_sampling import SMOTE
import pandas as pd
import numpy as np
import random

data = pd.read_csv(datadir)
print(data['ethnicity'])
data['ethnicity'].value_counts(dropna=False)
data['ethnicity'][0]
for i in range(0,len(data['ethnicity'])):
    print(data['ethnicity'][i])
    try:
      if "white" in data['ethnicity'][i].lower():
        data['ethnicity'][i] = 0
      elif "cau" in data['ethnicity'][i].lower():
        data['ethnicity'][i] = 0
      elif "black" in data['ethnicity'][i].lower():
        data['ethnicity'][i] =1
      elif "afri" in data['ethnicity'][i].lower():
        data['ethnicity'][i] =1
      elif "hispan" in data['ethnicity'][i].lower():
        data['ethnicity'][i] =2
      else:
        data['ethnicity'][i] =3
    except:
      data['ethnicity'][i]=0
      continue
data

data

labels = data['history_label']
labels

test =  list(zip(data['ethnicity'],data['index_rel']))
len(test)
test

X_train, X_test, y_train, y_test = train_test_split(test, labels,test_size=0.20)
X_train = tf.convert_to_tensor(X_train)
X_train.shape
X_test = tf.convert_to_tensor(X_test)
X_test.shape
y_train = np.array(y_train)
y_test = np.array(y_test)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)
print(X_train)
print(y_train)

from sklearn.externals.joblib import dump, load
dump(scaler, 'std_scaler.bin', compress=True)

from tensorflow.keras.regularizers import l1, l2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras import backend
from tensorflow.keras import optimizers
from tensorflow.keras.layers.experimental.preprocessing import Normalization

model = Sequential()
model.add(Dense(1024, activation='relu', name='inlayer'))
model.add(Dense(512, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(3, activation = 'softmax', name='outlayer'))
model

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.fit(X_train, y_train, batch_size=32, verbose=2, epochs=30)

testArr = np.array(X_test)
labelArr = np.array(y_test)
test_loss, test_acc = model.evaluate(testArr,  labelArr, verbose=2)

print('\nTest accuracy:', test_acc)





